---
title: "Computational Assignment 6"
author: Jason Adam
date: August 25, 2019
output: pdf_document
---

# Poisson & Zero-Inflated Poisson Regression  
In this assignment we will be fitting models and calculating the various summary statistics that are associated with Poisson and Zero-Inflated Poisson Regression.

For this assignment, we will be using the STRESS dataset. This includes information from about 650 adolescents in the US who were surveyed about the number of stressful life events they had experienced in the past year (STRESS). STRESS is an integer variable that represents counts of stressful events. The dataset also includes school and family related variables, which are assumed to be continuously distributed. These variables are:  

* COHES = measure of how well the adolescent gets along with their family (coded low to high)  
* ESTEEM = measure of self-esteem (coded low to high)  
* GRADES = past year's school grades (coded low to high)  
* SATTACH = measure of how well the adolescent likes and is attached to their school (coded low to high)

```{r echo=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.align = "center")
```

```{r}
library(dplyr)
library(tidyr)
library(readr)
library(ggplot2)
library(pscl)
library(knitr)
```

```{r}
mydf <- read_csv("STRESS.csv")
```

# 1. Summary Statistics  
For the STRESS variable, make a histogram and obtain summary statistics. Obtain a normal probability (Q-Q) plot for the STRESS variable. Is STRESS a normally distributed variable? What do you think is its most likely probability distribution for STRESS? Give a justification for the distribution you selected.

```{r fig.align="center", fig.width=8, fig.height=4}
par(mfrow = c(1, 2))

# Histogram
hist(mydf$STRESS, xlab = "Stress", main = "Histogram of Stress", col = "purple")

# Q-Q Plot
qqnorm(mydf$STRESS, main = "Normal Q-Q Plot (Stress)", pch = 19, col = "purple")
```

STRESS is definitely not normally distributed as evidenced by the histogram and Q-Q plot. The mean of STRESS is **`r round(mean(mydf$STRESS), digits = 3)`**, and the variance is **`r round(var(mydf$STRESS), digits = 3)`**. If we remove the zero values, the mean is **`r round(mean(mydf$STRESS[mydf$STRESS > 0]), digits = 3)`** and the variance is **`r round(var(mydf$STRESS[mydf$STRESS > 0]), digits = 3)`**. These values are very close indicating that either a Poisson probability distribution or a negative binomial distribution is a likely choice.

# 2. OLS Regression on STRESS  
Fit an OLS regression model to predict STRESS (Y) using COHES, ESTEEM, GRADES, SATTACH as explanatory variables (X). Obtain the typical diagnostic information and graphs.Discuss how well this model fits.Obtain predicted values (Y_hat) and plot them in a histogram.What issues do you see?  

Below we can see the summary output of the OLS model.

```{r}
ols1 <- lm(STRESS ~ COHES + ESTEEM + GRADES + SATTACH, data = mydf)
summary(ols1)
```

The linear model does a poor job of explaining the variance in STRESS. The adjusted R-squared is 0.07751, indicating that the independent variables only account for 7.75% of the variance in STRESS. A couple possible reasons are that the STRESS variable is not normally distributed and the relationships between the independent variables and STRESS are not linear. Each coefficient is negative which means that as the value of ESTEEM increases by a count of 1 (the adolescent's self-esteem), the STRESS level decreases by 0.04129. This is not a very plausible value to interpret as the values of STRESS must be non-negative integer values.

```{r fig.align="center", fig.width=8, fig.height=8}
par(mfrow=c(2,2))

plot(ols1)
```

In reviewing the diagnostic graphs of the OLS model, we can clearly see a pattern in the residuals vs fitted (top left) that indicates we are violating our assumption of homogeneity of variance. There also appear to be some values with high leverage.

```{r fig.align="center", fig.width=8, fig.height=4}
hist(ols1$fitted.values, main = "Histogram of Fitted Values", xlab = "Fitted Values", col = "orange")
```

The main thing that sticks out in the histogram of the fitted values is that they are relatively close to a normal distribution even though STRESS is not normally distributed. The mode of STRESS is 0 which is a very small component of the predicted values.

# 3. OLS Regression on ln(STRESS)  
Create a transformed variable on Y that is LN(Y). Fit an OLS regression model to predict LN(Y) using COHES, ESTEEM, GRADES, SATTACH as explanatory variables (X). Obtain the typical diagnostic information and graphs.Discuss how well this model fits.Obtain predicted values (LN(Y)_hat) and plot them in a histogram.What issues do you see?Does this correct the issue?  

Below is the model output for our second OLS regression model with STRESS log transformed.

```{r}
logSTRESS <- ifelse(mydf$STRESS == 0, 0, log(mydf$STRESS))
ols2 <- lm(logSTRESS ~ COHES + ESTEEM + GRADES + SATTACH, data = mydf)
summary(ols2)
```

For any observations of STRESS that were equal to zero, I left them as zero and took the natural log of any non-zero observations since the log of zero is negative infinity. The model performed almost the same as the first OLS model. The coefficients are all very small negative numbers, and the adjusted R-squared value is almost identical (0.07095). The log transformation of STRESS didn't have any noticeable impact in terms of accounting for it's variance with the independent variables. Again, the coefficients being non-integer values isn't particularly meaningful from a practical point of view since the values of STRESS are integers.  

```{r fig.align="center", fig.width=8, fig.height=8}
par(mfrow=c(2,2))

plot(ols2)
```

The diagnostic graphs show similar problems, violating our assumption of homogeneity of variance. There are high leveraged values as well. Overall, the OLS regression model doesn't appear to be a good fit for this type of data.

```{r fig.align="center", fig.width=8, fig.height=4}
hist(ols2$fitted.values, main = "Histogram of Fitted Values", xlab = "Fitted Values", col = "orange")
```

Once again, the fitted values are normally distributed (for the most part), but there are very few values predicted near zero despite that being the most commonly occurring value in the original data.

# 4. Poisson Regression on STRESS  
Use the glm() function to fit a Poisson Regression for STRESS (Y) using COHES, ESTEEM, GRADES, SATTACH as explanatory variables (X). Interpret the model’s coefficients and discuss how this model’s results compare to your answer for part 3). Similarly, fit an over-dispersed Poisson regression model using the same set of variables. How do these models compare?  

## Poisson Model

```{r}
pois1 <- glm(STRESS ~ COHES + ESTEEM + GRADES + SATTACH, data = mydf, family = "poisson")
summary(pois1)
```

The model coefficients are all still negative and very close to the model coefficients on the OLS model above. It's slightly difficult to interpret the coefficients of a Poisson models seeing as how they affect the change in the natural log of the dependent variable. In this case, a 1 unit increase in ESTEEM score (increase one integer value) results in a decrease of 0.023692 to the natural log of STRESS (when all other variables held constant). This means that as an adolescent has higher self-esteem, their stress level decreases when controlling for GRADES, COHES, and SATTACH.

## Negative Binomial Model  

```{r}
nbr1 <- MASS::glm.nb(STRESS ~ COHES + ESTEEM + GRADES + SATTACH, data = mydf)
summary(nbr1)
```

The negative binomial model has converged to an almost identical model as the Poisson regression model. The coefficients are nearly identical, however the AIC for the negative binomial model is 2283.6 while the AIC for the Poisson regression model is 2417.2. Following the general rule of thumb that a lower AIC is better, the second model is performing slightly better.  

# 5. Cohesion Predictions  
Based on the Poisson model in part 4), compute the predicted count of STRESS for those whose levels of family cohesion are less than one standard deviation below the mean (call this the low group), between one standard deviation below and one standard deviation above the mean (call this the middle group), and more than one standard deviation above the mean (high). What is the expected percent difference in the number of stressful events for those at high and low levels of family cohesion?  

Cohesion groups breakdown:  

```{r echo=TRUE}
# Mean & SD
meanCOHES <- mean(mydf$COHES)
sdCOHES <- sd(mydf$COHES)

# Calculate the groups
mydf <- mydf %>%
  mutate(groupCOHES = case_when(
    COHES < (meanCOHES - sdCOHES) ~ "Low",
    between(COHES, meanCOHES - sdCOHES, meanCOHES + sdCOHES) ~ "Middle",
    COHES > (meanCOHES + sdCOHES) ~ "High"
  ))

# View the counts
table(mydf$groupCOHES)
```

I'm pretty unsure of what this question is asking us to do.

# 6. AIC & BIC  
Compute the AICs and BICs from the Poisson Regression and the over-dispersed Poisson regression models from part 4). Is one better than the other?  

```{r}
poisBIC <- BIC(pois1)
nbrBIC <- BIC(nbr1)
```


The AIC from the Poisson Model is 2417.2 and the AIC from the Negative Binomial Model is 2283.6. The BIC from the Poisson model is `r poisBIC` and the BIC from the Negative Binomial model is `r nbrBIC`. The values are lower for both metrics on the over-dispersed model. This indicates that the negative binomial model is a better fit at this point.

# 7. Deviance Residuals  
Using the Poisson regression model from part 4), plot the deviance residuals by the predicted values. Discuss what this plot indicates about the regression model.

```{r}
plot(
  pois1$fitted.values,
  residuals(pois1, type = "deviance"),
  main = "Deviance Residuals vs Fitted Values",
  xlab = "Fitted Values",
  ylab = "Deviance Residuals",
  pch = 19,
  col = "orange"
)
```

I'm going to be perfectly honest, I don't really know how I'm supposed to interpret a graph like this. It looks like the residuals are not equally dispersed, but I don't think that's expected with Poisson regression.

# 8. Logistic Regression  
Create a new indicator variable (Y_IND) of STRESS that takes on a value of 0 if STRESS=0 and 1 if STRESS>0. This variable essentially measures is stress present, yes or no. Fit a logistic regression model to predict Y_IND using the variables using COHES, ESTEEM, GRADES, SATTACH as explanatory variables (X). Report the model, interpret the coefficients, obtain statistical information on goodness of fit, and discuss how well this model fits. Should you rerun the logistic regression analysis? If so, what should you do next?  

```{r}
mydf$Y_IND <- ifelse(mydf$STRESS == 0, 0, 1)

lr1 <- glm(Y_IND ~ COHES + ESTEEM + GRADES + SATTACH, data = mydf, family = "binomial")
summary(lr1)
```

```{r}
cohes_odds_change <- round(exp(lr1$coefficients[2]), digits = 3)
esteem_odds_change <- round(exp(lr1$coefficients[3]), digits = 3)
grades_odds_change <- round(exp(lr1$coefficients[4]), digits = 3)
sattach_odds_change <- round(exp(lr1$coefficients[5]), digits = 3)
```

Using the strategy of exponentiation, I get a percentage change equal to `r cohes_odds_change`. This means that for a one unit increase in COHES (Cohesion score increases by 1), the odds a person has stress decreases by 97.9% (assuming all other variables held constant). With ESTEEM I get a percentage change equal to `r esteem_odds_change` which means that for a one unit increase in feelings of self-esteem, the odds of an adolescent feeling Stress decreases by 98.1%. The remaining two coefficients both decrease the odds that an adolescent feels stress.

```{r}
logit_lr <-
  (
    lr1$coefficients[1] +  lr1$coefficients[2] * mydf$COHES + 
      lr1$coefficients[3] * mydf$ESTEEM + 
      lr1$coefficients[4] * mydf$GRADES + 
      lr1$coefficients[5] * mydf$SATTACH
  )

pi_lr <- exp(logit_lr) / (1 + exp(logit_lr))
pi_lr_thresh <- ifelse(pi_lr >= 0.5, 1, 0)
```

If we look at a table of the prediction threshold vs the dichotomous stress variable we can see that our logistic regression model has achieved an accuracy of 66.5%.

```{r}
table(mydf$Y_IND, pi_lr_thresh, dnn = c("STRESS Yes or No", "Predict"))
```

```{r}
accuracy_lr <- (422 + 11) / (422 + 11 + 8 + 210)
precision_lr <- 422 / (422 + 201)
recall_lr <- 422 / (422 + 8)
```

The precision of the logistic regression model is 67.7% (True Positive / True Positive + False Positive) and the recall of the model is 98.1% (True Positive / True Positive + False Negative).  

Considering the fact that the percentage of adolescents with stress in the original data is 66.05%, the logistic regression model was only a very slight improvement in classifying whether or not someone is going to have stress. This indicates that the associated variables aren't effective predictors.

I don't think it would be beneficial to re-run the logistic regression at this point. The model is not even classifying a high percentage of the observations correctly on the data with which it was trained. I don't think performing a test/train split would yield anything different at this juncture.

# 9. ZIP Regression  
It may be that there are two (or more) process at work that are overlapped and generating the distributions of STRESS(Y). What do you think those processes might be? To conduct a ZIP regression model by hand, fit a Logistic Regression model to predict if stress is present (Y_IND), and then use a Poisson Regression model to predict the number of stressful events (STRESS) conditioning on stress being present. Is it reasonable to use such a model? Combine the two fitted model to predict STRESS (Y). Obtained predicted values and residuals. How well does this model fit? HINT: You have to be thoughtful about this. It is not as straight forward as plug and chug!  

```{r echo=TRUE}
# Create Stress Level Variable
# Turns 0 into NA
mydf$StressLevel <- ifelse(mydf$STRESS == 0, NA, mydf$STRESS)

# Create binary stress variable
mydf$STRESS_binary <- ifelse(mydf$STRESS == 0, 0, 1)
```

```{r echo=TRUE}
# Logistic Regression Model on Dichotomous Stress Variable
lr9 <- glm(STRESS_binary ~ COHES + ESTEEM + GRADES + SATTACH, data = mydf, family = "binomial")

# Poisson Regression on Stress Level (excludes zeros)
pois9 <- glm(StressLevel ~ COHES + ESTEEM + GRADES + SATTACH, data = mydf, family = "poisson")
```

## Logistic Regression  
Below is the summary of the logistic regression. It's the same model as the previous section.

```{r}
summary(lr9)
```

If we look at the histogram of predicted probabilities, we can see that there are quite a few > 0.5 which means our logistic regression isn't doing a great job classifying 0 values.

```{r fig.width=8, fig.height=4}
hist(pi_lr, main = "Histogram of Probabilities", xlab = "Predicted Probabilities", col = "orange")
```


## Poisson Regression  
Below is the summary of the Poisson regression with the Stress Level variable as the dependent variable.

```{r}
summary(pois9)
```

## Combined Predictions

Below is a histogram of our combined predictions. We utilize the prediction probabilities from the logistic regression and the predicted values from the Poisson regression (without the zero values).

```{r echo=TRUE, fig.width=8, fig.height=4}
combined_yhat <- ifelse(pi_lr < 0.5, 0, pois9$fitted.values)

hist(combined_yhat,
     main = "Histogram of Predictions (ZIP Model)",
     xlab = "Predicted Stress",
     col = "orange")
```

The histogram looks much more in line with what we would expect based on our baseline data.  However, the number of zeros predicted still feels low since that was the highest value in the original data.

Below is a plot of the residuals. The residuals clearly follow a pattern. 

```{r fig.width=8, fig.height=4}
resid9 <- mydf$STRESS - combined_yhat

plot(
  mydf$STRESS,
  resid9,
  main = "Residuals vs Stress",
  xlab = "Stress",
  ylab = "Residuals",
  pch = 19,
  col = "orange"
)
```

Based on the plot of the residuals and the Stress variable, the model seem to fit better than previous models. There is very little variance at each value of Stress.  

# 10. ZIP Modeling  
Use the pscl package and the zeroinfl() function to Fit a ZIP model to predict STRESS(Y). You should do this twice, first using the same predictor variable for both parts of the ZIP model. Second, finding the best fitting model. Report the results and goodness of fit measures. Synthesize your findings across all of these models, to reflect on what you think would be a good modeling approach for this data.

Model 1:  

```{r}
zip10 <- zeroinfl(STRESS ~ COHES | COHES, data = mydf)
summary(zip10)
```

The count model coefficient for COHES represents a one unit increase in a feeling of cohesion results in a decrease of 0.015427 to the natural log of Stress. This is in the context of predicting the stress value IF the adolescent has stress.

```{r}
cohes_odds <- round(exp(-0.015427), digits = 3)
```

The zero-inflation model coefficient for cohesion is 0.02371. This means that the odds of having stress is increased by 98.5% when a feeling of cohesion is increased. This seems counter intuitive and is the opposite affect of the Poisson section of the model.

Model 2:  

```{r}
zip11 <- zeroinfl(STRESS ~ COHES + ESTEEM | COHES + ESTEEM + GRADES + SATTACH, data = mydf)
summary(zip11)
```

```{r}
zip10AIC <- round(AIC(zip10), digits = 3)
zip11AIC <- round(AIC(zip11), digits = 3)
```

The AIC of the second model is `r zip11AIC` which is lower than the AIC of `r zip10AIC` on the first model.

# Conclusion  
Overall, it seems like a zero-inflated model is a good choice for modeling this data. I will be perfectly honest that I felt a little lost when it came to interpreting the regression diagnostics on these models. The process is not very straightforward, and I struggled with understanding which model would be a better fit, especially when we're combining two models into one. This assignment is definitely not my best work, unfortunately.





